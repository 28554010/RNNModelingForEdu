{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Edu\n",
    "Vinitra Swamy, Madeline Wu, Wilton Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics \n",
    "\n",
    "filename = 'skill_builder_data_corrected.csv'\n",
    "df = pd.read_csv(filename, encoding='ISO-8859-1', low_memory=False)\n",
    "df = df[(df['original'] == 1) & (df['attempt_count'] == 1) & ~(df['skill_name'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>assistment_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>original</th>\n",
       "      <th>correct</th>\n",
       "      <th>attempt_count</th>\n",
       "      <th>ms_first_response</th>\n",
       "      <th>tutor_mode</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>student_class_id</th>\n",
       "      <th>position</th>\n",
       "      <th>type</th>\n",
       "      <th>base_sequence_id</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>school_id</th>\n",
       "      <th>hint_count</th>\n",
       "      <th>hint_total</th>\n",
       "      <th>overlap_time</th>\n",
       "      <th>template_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>first_action</th>\n",
       "      <th>bottom_hint</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>opportunity_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33022537</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33139</td>\n",
       "      <td>51424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32454</td>\n",
       "      <td>tutor</td>\n",
       "      <td>algebra</td>\n",
       "      <td>5948</td>\n",
       "      <td>13241</td>\n",
       "      <td>126</td>\n",
       "      <td>MasterySection</td>\n",
       "      <td>5948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>22763</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32454</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33022709</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33150</td>\n",
       "      <td>51435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4922</td>\n",
       "      <td>tutor</td>\n",
       "      <td>algebra</td>\n",
       "      <td>5948</td>\n",
       "      <td>13241</td>\n",
       "      <td>126</td>\n",
       "      <td>MasterySection</td>\n",
       "      <td>5948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>22763</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4922</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35450295</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33110</td>\n",
       "      <td>51395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4859</td>\n",
       "      <td>tutor</td>\n",
       "      <td>algebra</td>\n",
       "      <td>5948</td>\n",
       "      <td>11816</td>\n",
       "      <td>22</td>\n",
       "      <td>MasterySection</td>\n",
       "      <td>5948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>22763</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4859</td>\n",
       "      <td>30059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35450555</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33172</td>\n",
       "      <td>51457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16031</td>\n",
       "      <td>tutor</td>\n",
       "      <td>algebra</td>\n",
       "      <td>5948</td>\n",
       "      <td>11816</td>\n",
       "      <td>22</td>\n",
       "      <td>MasterySection</td>\n",
       "      <td>5948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>22763</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16031</td>\n",
       "      <td>30060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35450573</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33174</td>\n",
       "      <td>51459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15047</td>\n",
       "      <td>tutor</td>\n",
       "      <td>algebra</td>\n",
       "      <td>5948</td>\n",
       "      <td>11816</td>\n",
       "      <td>22</td>\n",
       "      <td>MasterySection</td>\n",
       "      <td>5948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>22763</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15047</td>\n",
       "      <td>30060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  assignment_id  user_id  assistment_id  problem_id  original  \\\n",
       "0  33022537         277618    64525          33139       51424         1   \n",
       "1  33022709         277618    64525          33150       51435         1   \n",
       "3  35450295         220674    70363          33110       51395         1   \n",
       "5  35450555         220674    70363          33172       51457         1   \n",
       "6  35450573         220674    70363          33174       51459         1   \n",
       "\n",
       "   correct  attempt_count  ms_first_response tutor_mode answer_type  \\\n",
       "0        1              1              32454      tutor     algebra   \n",
       "1        1              1               4922      tutor     algebra   \n",
       "3        1              1               4859      tutor     algebra   \n",
       "5        1              1              16031      tutor     algebra   \n",
       "6        1              1              15047      tutor     algebra   \n",
       "\n",
       "   sequence_id  student_class_id  position            type  base_sequence_id  \\\n",
       "0         5948             13241       126  MasterySection              5948   \n",
       "1         5948             13241       126  MasterySection              5948   \n",
       "3         5948             11816        22  MasterySection              5948   \n",
       "5         5948             11816        22  MasterySection              5948   \n",
       "6         5948             11816        22  MasterySection              5948   \n",
       "\n",
       "   skill_id       skill_name  teacher_id  school_id  hint_count  hint_total  \\\n",
       "0       1.0  Box and Whisker       22763         73           0           3   \n",
       "1       1.0  Box and Whisker       22763         73           0           3   \n",
       "3       1.0  Box and Whisker       22763         73           0           3   \n",
       "5       1.0  Box and Whisker       22763         73           0           4   \n",
       "6       1.0  Box and Whisker       22763         73           0           4   \n",
       "\n",
       "   overlap_time  template_id  answer_id answer_text  first_action  \\\n",
       "0         32454        30799        NaN          26             0   \n",
       "1          4922        30799        NaN          55             0   \n",
       "3          4859        30059        NaN          41             0   \n",
       "5         16031        30060        NaN          12             0   \n",
       "6         15047        30060        NaN           6             0   \n",
       "\n",
       "   bottom_hint  opportunity  opportunity_original  \n",
       "0          NaN            1                   1.0  \n",
       "1          NaN            2                   2.0  \n",
       "3          NaN            2                   2.0  \n",
       "5          NaN            4                   4.0  \n",
       "6          NaN            5                   5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def generate_datasets():\n",
    "    users_list = df['user_id'].unique()\n",
    "    skill_list = df['skill_name'].unique()\n",
    "\n",
    "    # 不用原来的skill_id，因为有多skill的情况。\n",
    "    # 把所有不同skill_name都当成一个单独skill\n",
    "    # 但是这种处理方法还是不对！\n",
    "    '''\n",
    "        For the skill builder dataset, different skills for the same data record \n",
    "        are in different rows. This means if a student answers a multi skill \n",
    "        question, this record is duplicated several times, and each duplication \n",
    "        is tagged with one of the multi skills.    \n",
    "    '''\n",
    "    skill_dict = dict(zip(skill_list, np.arange(len(skill_list), dtype='int32') + 1))\n",
    "    response_list = []\n",
    "    skill_list = []\n",
    "    assistment_list = []\n",
    "    \n",
    "    counter = 0\n",
    "    for user in users_list:\n",
    "        # 只取一个学生的\n",
    "        sub_df = df[df['user_id'] == user]\n",
    "        if len(sub_df) > 100:\n",
    "            # 每个学生只取前100次回答\n",
    "            first_hundred = sub_df.iloc[0:100]\n",
    "            response_df = pd.DataFrame(index=[counter], columns=['student_id']+['r'+str(i) for i in range(100)])\n",
    "            skill_df = pd.DataFrame(index=[counter], columns=['student_id']+['s'+str(i) for i in range(100)])\n",
    "            assistment_df = pd.DataFrame(index=[counter], columns=['student_id']+['a'+str(i) for i in range(100)])\n",
    "            \n",
    "            # 第一格都是user_id\n",
    "            response_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            skill_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            assistment_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            \n",
    "            # 用到 user_id, correct, skill_name, assistment_id 这几个列\n",
    "            for i in range(100):\n",
    "                response_df.iloc[0, i+1] = first_hundred.iloc[i]['correct']\n",
    "                skill_df.iloc[0, i+1] = skill_dict[first_hundred.iloc[i]['skill_name']]\n",
    "                assistment_df.iloc[0, i+1] = first_hundred.iloc[i]['assistment_id']\n",
    "            counter += 1\n",
    "            response_list.append(response_df)\n",
    "            skill_list.append(skill_df)\n",
    "            assistment_list.append(assistment_df)\n",
    "    \n",
    "    response_df = pd.concat(response_list)\n",
    "    skill_df = pd.concat(skill_list)\n",
    "    assistment_df = pd.concat(assistment_list)\n",
    "    \n",
    "    return skill_dict, response_df, skill_df, assistment_df\n",
    "\n",
    "# 这样写很好。明确上一步结果是这4个东西！\n",
    "skill_dict, response_df, skill_df, assistment_df = generate_datasets()\n",
    "\n",
    "with open('skill_dict.json', 'w', encoding='utf-8') as f:\n",
    "    to_dump_dict = {}\n",
    "    for key, value in skill_dict.items():\n",
    "        to_dump_dict[key] = str(value)\n",
    "    json.dump(to_dump_dict, f)\n",
    "response_df.to_csv('correct.tsv', sep='\\t')\n",
    "skill_df.to_csv('skill.tsv', sep='\\t')\n",
    "assistment_df.to_csv('assistment_id.tsv', sep='\\t')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_df = pd.read_csv('correct.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "skill_df = pd.read_csv('skill.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "assistment_df = pd.read_csv('assistment_id.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "skill_dict = {}\n",
    "with open('skill_dict.json', 'r', encoding='utf-8') as f:\n",
    "    loaded = json.load(f)\n",
    "    for k, v in loaded.items():\n",
    "        skill_dict[k] = int(v)\n",
    "\n",
    "skill_num = len(skill_dict) + 1 # including 0\n",
    "\n",
    "def one_hot(skill_matrix, vocab_size):\n",
    "    '''\n",
    "    params:\n",
    "        skill_matrix: 2-D matrix (student, skills)\n",
    "        vocal_size: size of the vocabulary\n",
    "    returns:\n",
    "        a ndarray with a shape like (student, sequence_len, vocab_size)\n",
    "    '''\n",
    "    seq_len = skill_matrix.shape[1]\n",
    "    result = np.zeros((skill_matrix.shape[0], seq_len, vocab_size))\n",
    "    for i in range(skill_matrix.shape[0]):\n",
    "        result[i, np.arange(seq_len), skill_matrix[i]] = 1.\n",
    "    return result\n",
    "\n",
    "def dkt_one_hot(skill_matrix, response_matrix, vocab_size):\n",
    "    seq_len = skill_matrix.shape[1]\n",
    "    skill_response_array = np.zeros((skill_matrix.shape[0], seq_len, 2 * vocab_size))\n",
    "    for i in range(skill_matrix.shape[0]):\n",
    "        skill_response_array[i, np.arange(seq_len), 2 * skill_matrix[i] + response_matrix[i]] = 1.\n",
    "    return skill_response_array\n",
    "\n",
    "def preprocess(skill_df, response_df, skill_num):\n",
    "    skill_matrix = skill_df.iloc[:, 1:].values\n",
    "    response_array = response_df.iloc[:, 1:].values\n",
    "    skill_array = one_hot(skill_matrix, skill_num)\n",
    "    skill_response_array = dkt_one_hot(skill_matrix, response_array, skill_num)\n",
    "    return skill_array, response_array, skill_response_array\n",
    "    \n",
    "\n",
    "skill_array, response_array, skill_response_array = preprocess(skill_df, response_df, skill_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skill2skill\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_skills (InputLayer)    (None, 99, 111)           0         \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 99, 64)            45056     \n",
      "_________________________________________________________________\n",
      "probability (TimeDistributed (None, 99, 111)           7215      \n",
      "=================================================================\n",
      "Total params: 52,271\n",
      "Trainable params: 52,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dkt\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_skills (InputLayer)        (None, 99, 222)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_layer (LSTM)                (None, 99, 64)        73472       input_skills[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "probability_for_each (TimeDistri (None, 99, 111)       7215        lstm_layer[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "next_skill_tested (InputLayer)   (None, 99, 111)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "multiply (Multiply)              (None, 99, 111)       0           probability_for_each[0][0]       \n",
      "                                                                   next_skill_tested[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "reduce_dim (Lambda)              (None, 99, 1)         0           multiply[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 80,687\n",
      "Trainable params: 80,687\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed, Lambda, multiply\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "\n",
    "def build_skill2skill_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input = Input(shape=input_shape, name='input_skills')\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout,\n",
    "                name='lstm_layer')(input)\n",
    "    output = TimeDistributed(Dense(input_shape[-1], activation='softmax'), name='probability')(lstm)\n",
    "    model = Model(inputs=[input], outputs=[output])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def reduce_dim(x):\n",
    "    x = K.max(x, axis=-1, keepdims=True)\n",
    "    return x\n",
    "\n",
    "def build_dkt_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input_skills = Input(shape=input_shape, name='input_skills')\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout,\n",
    "                name='lstm_layer')(input_skills)\n",
    "    dense = TimeDistributed(Dense(int(input_shape[-1]/2), activation='sigmoid'), name='probability_for_each')(lstm)\n",
    "    \n",
    "    skill_next = Input(shape=(input_shape[0], int(input_shape[1]/2)), name='next_skill_tested')\n",
    "    merged = multiply([dense, skill_next], name='multiply')\n",
    "    reduced = Lambda(reduce_dim, output_shape=(input_shape[0], 1), name='reduce_dim')(merged)\n",
    "    \n",
    "    model = Model(inputs=[input_skills, skill_next], outputs=[reduced])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "print('skill2skill')\n",
    "skill2skill_model = build_skill2skill_model((99, skill_num), lstm_dim=64)\n",
    "\n",
    "print('dkt')\n",
    "dkt_model = build_dkt_model((99, 2 * skill_num), lstm_dim=64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 467 samples, validate on 117 samples\n",
      "Epoch 1/20\n",
      "467/467 [==============================] - 8s - loss: 4.6379 - acc: 0.1892 - val_loss: 4.6019 - val_acc: 0.17\n",
      "Epoch 2/20\n",
      "467/467 [==============================] - 7s - loss: 4.3080 - acc: 0.2725 - val_loss: 4.5962 - val_acc: 0.05\n",
      "Epoch 3/20\n",
      "467/467 [==============================] - 8s - loss: 3.6597 - acc: 0.1848 - val_loss: 4.1307 - val_acc: 0.14\n",
      "Epoch 4/20\n",
      "467/467 [==============================] - 7s - loss: 3.1340 - acc: 0.2661 - val_loss: 3.8382 - val_acc: 0.19\n",
      "Epoch 5/20\n",
      "467/467 [==============================] - 7s - loss: 2.7912 - acc: 0.3407 - val_loss: 3.5741 - val_acc: 0.24\n",
      "Epoch 6/20\n",
      "467/467 [==============================] - 8s - loss: 2.4974 - acc: 0.3993 - val_loss: 3.3062 - val_acc: 0.30\n",
      "Epoch 7/20\n",
      "467/467 [==============================] - 7s - loss: 2.2484 - acc: 0.4598 - val_loss: 3.0888 - val_acc: 0.37\n",
      "Epoch 8/20\n",
      "467/467 [==============================] - 7s - loss: 2.0336 - acc: 0.5335 - val_loss: 2.8829 - val_acc: 0.42\n",
      "Epoch 9/20\n",
      "467/467 [==============================] - 7s - loss: 1.8528 - acc: 0.5772 - val_loss: 2.6949 - val_acc: 0.46\n",
      "Epoch 10/20\n",
      "467/467 [==============================] - 7s - loss: 1.6849 - acc: 0.6217 - val_loss: 2.5130 - val_acc: 0.47\n",
      "Epoch 11/20\n",
      "467/467 [==============================] - 6s - loss: 1.5558 - acc: 0.6532 - val_loss: 2.3544 - val_acc: 0.50\n",
      "Epoch 12/20\n",
      "467/467 [==============================] - 7s - loss: 1.4336 - acc: 0.6787 - val_loss: 2.1872 - val_acc: 0.53\n",
      "Epoch 13/20\n",
      "467/467 [==============================] - 7s - loss: 1.3276 - acc: 0.7050 - val_loss: 2.0680 - val_acc: 0.54\n",
      "Epoch 14/20\n",
      "467/467 [==============================] - 7s - loss: 1.2328 - acc: 0.7225 - val_loss: 1.9077 - val_acc: 0.58\n",
      "Epoch 15/20\n",
      "467/467 [==============================] - 8s - loss: 1.1566 - acc: 0.7344 - val_loss: 1.8513 - val_acc: 0.59\n",
      "Epoch 16/20\n",
      "467/467 [==============================] - 9s - loss: 1.1003 - acc: 0.7438 - val_loss: 1.6935 - val_acc: 0.62\n",
      "Epoch 17/20\n",
      "467/467 [==============================] - 7s - loss: 1.0384 - acc: 0.7536 - val_loss: 1.5925 - val_acc: 0.65\n",
      "Epoch 18/20\n",
      "467/467 [==============================] - 8s - loss: 0.9800 - acc: 0.7631 - val_loss: 1.5151 - val_acc: 0.66\n",
      "Epoch 19/20\n",
      "467/467 [==============================] - 7s - loss: 0.9351 - acc: 0.7747 - val_loss: 1.4566 - val_acc: 0.67\n",
      "Epoch 20/20\n",
      "467/467 [==============================] - 7s - loss: 0.8956 - acc: 0.7808 - val_loss: 1.4103 - val_acc: 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112e2b710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train skill2skill\n",
    "skill2skill_model.fit(skill_array[:, 0:-1], \n",
    "                      skill_array[:, 1:],\n",
    "                      epochs=20, \n",
    "                      batch_size=32, \n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 467 samples, validate on 117 samples\n",
      "Epoch 1/20\n",
      "467/467 [==============================] - 10s - loss: 0.6702 - acc: 0.7641 - val_loss: 0.6544 - val_acc: 0.808\n",
      "Epoch 2/20\n",
      "467/467 [==============================] - 7s - loss: 0.5934 - acc: 0.8380 - val_loss: 0.5707 - val_acc: 0.79\n",
      "Epoch 3/20\n",
      "467/467 [==============================] - 6s - loss: 0.4667 - acc: 0.8389 - val_loss: 0.4911 - val_acc: 0.83\n",
      "Epoch 4/20\n",
      "467/467 [==============================] - 7s - loss: 0.4129 - acc: 0.8494 - val_loss: 0.4507 - val_acc: 0.83\n",
      "Epoch 5/20\n",
      "467/467 [==============================] - 7s - loss: 0.3942 - acc: 0.8514 - val_loss: 0.4455 - val_acc: 0.83\n",
      "Epoch 6/20\n",
      "467/467 [==============================] - 7s - loss: 0.3851 - acc: 0.8529 - val_loss: 0.4397 - val_acc: 0.83\n",
      "Epoch 7/20\n",
      "467/467 [==============================] - 7s - loss: 0.3797 - acc: 0.8563 - val_loss: 0.4322 - val_acc: 0.83\n",
      "Epoch 8/20\n",
      "467/467 [==============================] - 9s - loss: 0.3753 - acc: 0.8572 - val_loss: 0.4392 - val_acc: 0.83\n",
      "Epoch 9/20\n",
      "467/467 [==============================] - 7s - loss: 0.3717 - acc: 0.8569 - val_loss: 0.4175 - val_acc: 0.83\n",
      "Epoch 10/20\n",
      "467/467 [==============================] - 8s - loss: 0.3695 - acc: 0.8570 - val_loss: 0.4284 - val_acc: 0.83\n",
      "Epoch 11/20\n",
      "467/467 [==============================] - 7s - loss: 0.3658 - acc: 0.8574 - val_loss: 0.4217 - val_acc: 0.83\n",
      "Epoch 12/20\n",
      "467/467 [==============================] - 7s - loss: 0.3613 - acc: 0.8585 - val_loss: 0.4205 - val_acc: 0.83\n",
      "Epoch 13/20\n",
      "467/467 [==============================] - 7s - loss: 0.3593 - acc: 0.8586 - val_loss: 0.4236 - val_acc: 0.83\n",
      "Epoch 14/20\n",
      "467/467 [==============================] - 6s - loss: 0.3579 - acc: 0.8595 - val_loss: 0.4226 - val_acc: 0.83\n",
      "Epoch 15/20\n",
      "467/467 [==============================] - 6s - loss: 0.3539 - acc: 0.8605 - val_loss: 0.4078 - val_acc: 0.84\n",
      "Epoch 16/20\n",
      "467/467 [==============================] - 7s - loss: 0.3508 - acc: 0.8613 - val_loss: 0.4125 - val_acc: 0.84\n",
      "Epoch 17/20\n",
      "467/467 [==============================] - 6s - loss: 0.3511 - acc: 0.8606 - val_loss: 0.4000 - val_acc: 0.84\n",
      "Epoch 18/20\n",
      "467/467 [==============================] - 7s - loss: 0.3478 - acc: 0.8618 - val_loss: 0.4022 - val_acc: 0.84\n",
      "Epoch 19/20\n",
      "467/467 [==============================] - 9s - loss: 0.3459 - acc: 0.8624 - val_loss: 0.4064 - val_acc: 0.84\n",
      "Epoch 20/20\n",
      "467/467 [==============================] - 8s - loss: 0.3457 - acc: 0.8622 - val_loss: 0.4037 - val_acc: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e577cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dkt_model.fit([skill_response_array[:, 0:-1], skill_array[:, 1:]],\n",
    "              response_array[:, 1:, np.newaxis],\n",
    "              epochs=20, \n",
    "              batch_size=32, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "#### What were the 5 most common and 5 least common skills in this dataset? What percentage of responses are associated with the most common skill?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 most common skills were: 87: Equation Solving Two or Fewer Steps, 30: Conversion of Fraction Decimals Percents, 71: Addition and Subtraction Fractions, 68: Addition and Subtraction Integers, 33: Ordering Fractions. \n",
    "\n",
    "The 5 least common skills were: 28: Reading a Ruler or Scale, 102: Recognize Quadratic Pattern, 98: Finding Slope from Ordered Pairs, 96: Finding Slope From Situation, 99: Distributive Property.\n",
    "\n",
    "87 (Equation Solving Two or Fewer Steps) was the most common skill.\n",
    "\n",
    "5.77% of the responses corresponded with this skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most common skills are: ['87: Equation Solving Two or Fewer Steps', '30: Conversion of Fraction Decimals Percents', '71: Addition and Subtraction Fractions', '68: Addition and Subtraction Integers', '33: Ordering Fractions']\n",
      "5 least common skills are: ['28: Reading a Ruler or Scale', '102: Recognize Quadratic Pattern', '98: Finding Slope from Ordered Pairs', '96: Finding Slope From Situation', '99: Distributive Property']\n"
     ]
    }
   ],
   "source": [
    "sorted_df = df.groupby(by=['skill_name']).count()\n",
    "\n",
    "most = sorted_df.sort_values(by='order_id', ascending=[False]).index[0:5]\n",
    "print(\"5 most common skills are:\", [str(skill_dict[skill]) + \": \" + skill for skill in most])\n",
    "\n",
    "least = sorted_df.sort_values(by='order_id', ascending=[True]).index[0:5]\n",
    "print(\"5 least common skills are:\", [str(skill_dict[skill]) + \": \" + skill for skill in least])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057708219855885375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_df = sorted_df.sort_values(by='order_id', ascending=[False])\n",
    "total = most_df.ix[:,0].sum()\n",
    "most_common_skill = most_df.iloc[0,0]\n",
    "\n",
    "most_common_skill / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "#### Train the sequence prediction model using a randomly selected 70% (training set) of students' data and predict on the remaining 30% (test set). What was the overall accuracy of skill prediction in the test set? What were the top 5 hardest and easiest to predict skills? Describe the metric you chose to represent hard/easy prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 82 samples\n",
      "Epoch 1/20\n",
      "326/326 [==============================] - 5s - loss: 0.9941 - acc: 0.7658 - val_loss: 0.8900 - val_acc: 0.78\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 4s - loss: 0.9478 - acc: 0.7728 - val_loss: 0.8582 - val_acc: 0.79\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 5s - loss: 0.9124 - acc: 0.7824 - val_loss: 0.8341 - val_acc: 0.80\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 5s - loss: 0.8815 - acc: 0.7893 - val_loss: 0.8110 - val_acc: 0.80\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 6s - loss: 0.8542 - acc: 0.7932 - val_loss: 0.7888 - val_acc: 0.81\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 5s - loss: 0.8323 - acc: 0.7987 - val_loss: 0.7690 - val_acc: 0.81\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 5s - loss: 0.8112 - acc: 0.8031 - val_loss: 0.7623 - val_acc: 0.81\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 6s - loss: 0.7992 - acc: 0.8054 - val_loss: 0.7416 - val_acc: 0.81\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 5s - loss: 0.7801 - acc: 0.8093 - val_loss: 0.7295 - val_acc: 0.82\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 7s - loss: 0.7701 - acc: 0.8127 - val_loss: 0.7217 - val_acc: 0.82\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 6s - loss: 0.7571 - acc: 0.8156 - val_loss: 0.7072 - val_acc: 0.82\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 7s - loss: 0.7405 - acc: 0.8182 - val_loss: 0.6940 - val_acc: 0.82\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 6s - loss: 0.7239 - acc: 0.8212 - val_loss: 0.6802 - val_acc: 0.83\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 6s - loss: 0.7105 - acc: 0.8239 - val_loss: 0.6751 - val_acc: 0.83\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 5s - loss: 0.7001 - acc: 0.8242 - val_loss: 0.6642 - val_acc: 0.83\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 5s - loss: 0.6904 - acc: 0.8274 - val_loss: 0.6557 - val_acc: 0.83\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 5s - loss: 0.6794 - acc: 0.8290 - val_loss: 0.6477 - val_acc: 0.83\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 7s - loss: 0.6698 - acc: 0.8319 - val_loss: 0.6430 - val_acc: 0.84\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 5s - loss: 0.6666 - acc: 0.8305 - val_loss: 0.6338 - val_acc: 0.84\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 5s - loss: 0.6540 - acc: 0.8348 - val_loss: 0.6250 - val_acc: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123eccc88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = skill_array[:, 0:-1]\n",
    "y = skill_array[:, 1:]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, test_size=0.3)\n",
    "\n",
    "skill2skill_model.fit(X_train, \n",
    "                      y_train,\n",
    "                      epochs=20, \n",
    "                      batch_size=32, \n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = skill2skill_model.predict(X_test)\n",
    "one_hot_predictions = []\n",
    "for i in np.arange(len(predictions)):\n",
    "    one_hot_layer = []\n",
    "    for j in np.arange(len(predictions[0])):\n",
    "            index_of_max = np.argmax(predictions[i][j])\n",
    "            one_hot_version = np.zeros(skill_num)\n",
    "            one_hot_version[index_of_max] = 1\n",
    "            one_hot_layer.append(one_hot_version)\n",
    "    one_hot_predictions.append(one_hot_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323576675849403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate = np.count_nonzero(y_test - one_hot_predictions)/2/(y_test.shape[0] * y_test.shape[1])\n",
    "1-error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the test set is 83.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying top 5 hardest/easiest to predict skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "one_hot_predictions - y_test\n",
    "\n",
    "correct = {}\n",
    "incorrect = {}\n",
    "\n",
    "for i in range(len(one_hot_predictions)):\n",
    "    for j in range(len(one_hot_predictions[0])):\n",
    "        prediction = one_hot_predictions[i][j]\n",
    "        actual = y_test[i][j]\n",
    "        \n",
    "        comparison = prediction - actual\n",
    "        position = np.argmax(actual) + 1\n",
    "        if 1 not in comparison and -1 not in comparison:\n",
    "            if position in correct.keys():\n",
    "                correct[position] += 1\n",
    "            else:\n",
    "                correct[position] = 1\n",
    "        else:\n",
    "            if position in incorrect.keys():\n",
    "                incorrect[position] += 1\n",
    "            else:\n",
    "                incorrect[position] = 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(47, 0.9225225225225225),\n",
       "  (3, 0.9242579324462641),\n",
       "  (31, 0.9281894576012223),\n",
       "  (69, 0.9320388349514563),\n",
       "  (2, 0.9785714285714285)],\n",
       " [(74, 1.0), (89, 1.0), (76, 1.0), (79, 1.0), (82, 1.0)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in np.arange(1, 112):\n",
    "    if i not in correct.keys():\n",
    "        correct[i] = 0\n",
    "    if i not in incorrect.keys():\n",
    "        incorrect[i] = 0\n",
    "        \n",
    "totals = [correct[i] + incorrect[i] for i in np.arange(1, 112)]\n",
    "for i in range(1, len(correct)+1):\n",
    "    if totals[i-1] != 0:\n",
    "        correct[i] = correct[i] / totals[i-1]\n",
    "        incorrect[i] = incorrect[i] / totals[i-1]\n",
    "    else:\n",
    "        if correct[i] != 0 or incorrect[i] != 0:\n",
    "            print(\"something is incorrect lol\")\n",
    "\n",
    "sorted_correct = sorted(correct.items(), key=operator.itemgetter(1))\n",
    "easiest_to_identify_skills = sorted_correct[-5:]\n",
    "sorted_incorrect = sorted(incorrect.items(), key=operator.itemgetter(1))\n",
    "hardest_to_identify_skills = sorted_incorrect[-5:]\n",
    "\n",
    "easiest_to_identify_skills, hardest_to_identify_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined easiest to identify skills as the skills that had the highest proportion of accurate prediction. We decided not to use mere accurate prediction as a metric because it is unfair to skills that don't appear as often in the dataset. We defined hardest to identify skills analogously -- those that had the highest proportion in the cases of inaccurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "#### Modify parameters of the network to increase accuracy (e.g. number of hidden nodes, optimizer, number of RNN layers, number of epochs, creating a validation set and stopping training when the validation set accuracy decreases). What were your accuracy results with respect to the hyper parameters you tuned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betterskill2skill\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 99, 111)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 99, 64)            45056     \n",
      "_________________________________________________________________\n",
      "probability (TimeDistributed (None, 99, 111)           7215      \n",
      "=================================================================\n",
      "Total params: 52,271\n",
      "Trainable params: 52,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_betterskill2skill_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input = Input(shape=input_shape)\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout)(input)\n",
    "    output = TimeDistributed(Dense(input_shape[-1], activation='softmax'), name='probability')(lstm)\n",
    "    model = Model(inputs=[input], outputs=[output])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "print('betterskill2skill')\n",
    "betterskill2skill_model = build_betterskill2skill_model((99, skill_num), lstm_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 82 samples\n",
      "Epoch 1/200\n",
      "326/326 [==============================] - 4s - loss: 4.7042 - acc: 0.0181 - val_loss: 4.6814 - val_acc: 0.04\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s - loss: 4.6732 - acc: 0.0538 - val_loss: 4.6489 - val_acc: 0.11\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s - loss: 4.6412 - acc: 0.1379 - val_loss: 4.6144 - val_acc: 0.24\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s - loss: 4.6071 - acc: 0.2600 - val_loss: 4.5761 - val_acc: 0.41\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 2s - loss: 4.5690 - acc: 0.4088 - val_loss: 4.5308 - val_acc: 0.47\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s - loss: 4.5225 - acc: 0.4580 - val_loss: 4.4721 - val_acc: 0.50\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s - loss: 4.4602 - acc: 0.4716 - val_loss: 4.3838 - val_acc: 0.46\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 2s - loss: 4.3621 - acc: 0.4114 - val_loss: 4.2248 - val_acc: 0.33\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s - loss: 4.2015 - acc: 0.2710 - val_loss: 4.0428 - val_acc: 0.19\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s - loss: 4.0546 - acc: 0.2025 - val_loss: 3.9131 - val_acc: 0.22\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s - loss: 3.9347 - acc: 0.2315 - val_loss: 3.7825 - val_acc: 0.24\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s - loss: 3.7957 - acc: 0.2426 - val_loss: 3.6624 - val_acc: 0.25\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s - loss: 3.6767 - acc: 0.2602 - val_loss: 3.5358 - val_acc: 0.29\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s - loss: 3.5447 - acc: 0.2876 - val_loss: 3.4003 - val_acc: 0.31\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s - loss: 3.4209 - acc: 0.3039 - val_loss: 3.2773 - val_acc: 0.31\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 2s - loss: 3.3105 - acc: 0.3026 - val_loss: 3.1698 - val_acc: 0.32\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s - loss: 3.1955 - acc: 0.3228 - val_loss: 3.0414 - val_acc: 0.34\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 2s - loss: 3.0803 - acc: 0.3414 - val_loss: 2.9379 - val_acc: 0.35\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s - loss: 2.9728 - acc: 0.3499 - val_loss: 2.8371 - val_acc: 0.36\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s - loss: 2.8647 - acc: 0.3688 - val_loss: 2.7273 - val_acc: 0.39\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 2s - loss: 2.7685 - acc: 0.3887 - val_loss: 2.6421 - val_acc: 0.39\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s - loss: 2.6793 - acc: 0.4013 - val_loss: 2.5541 - val_acc: 0.42\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s - loss: 2.5942 - acc: 0.4171 - val_loss: 2.4743 - val_acc: 0.42\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s - loss: 2.5261 - acc: 0.4320 - val_loss: 2.4238 - val_acc: 0.45\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 2s - loss: 2.4516 - acc: 0.4429 - val_loss: 2.3390 - val_acc: 0.42\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 2s - loss: 2.3863 - acc: 0.4285 - val_loss: 2.2706 - val_acc: 0.45\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s - loss: 2.3116 - acc: 0.4704 - val_loss: 2.2117 - val_acc: 0.46\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 2s - loss: 2.2475 - acc: 0.4731 - val_loss: 2.1509 - val_acc: 0.48\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 2s - loss: 2.1848 - acc: 0.4884 - val_loss: 2.0879 - val_acc: 0.49\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s - loss: 2.1264 - acc: 0.4958 - val_loss: 2.0429 - val_acc: 0.50\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 2s - loss: 2.0658 - acc: 0.5173 - val_loss: 1.9868 - val_acc: 0.52\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s - loss: 2.0198 - acc: 0.5284 - val_loss: 1.9273 - val_acc: 0.53\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s - loss: 1.9620 - acc: 0.5436 - val_loss: 1.8835 - val_acc: 0.54\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s - loss: 1.9136 - acc: 0.5515 - val_loss: 1.8376 - val_acc: 0.55\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s - loss: 1.8681 - acc: 0.5598 - val_loss: 1.7928 - val_acc: 0.56\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s - loss: 1.8232 - acc: 0.5719 - val_loss: 1.7542 - val_acc: 0.57\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s - loss: 1.7796 - acc: 0.5865 - val_loss: 1.7068 - val_acc: 0.59\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s - loss: 1.7374 - acc: 0.5958 - val_loss: 1.6706 - val_acc: 0.59\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s - loss: 1.6978 - acc: 0.6010 - val_loss: 1.6310 - val_acc: 0.61\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s - loss: 1.6625 - acc: 0.6129 - val_loss: 1.6047 - val_acc: 0.62\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 2s - loss: 1.6339 - acc: 0.6230 - val_loss: 1.5738 - val_acc: 0.64\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s - loss: 1.5978 - acc: 0.6318 - val_loss: 1.5397 - val_acc: 0.63\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s - loss: 1.5673 - acc: 0.6356 - val_loss: 1.5167 - val_acc: 0.64\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s - loss: 1.5311 - acc: 0.6466 - val_loss: 1.4815 - val_acc: 0.66\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s - loss: 1.5019 - acc: 0.6568 - val_loss: 1.4598 - val_acc: 0.66\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s - loss: 1.4737 - acc: 0.6620 - val_loss: 1.4344 - val_acc: 0.67\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s - loss: 1.4474 - acc: 0.6688 - val_loss: 1.3989 - val_acc: 0.68\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s - loss: 1.4257 - acc: 0.6745 - val_loss: 1.3829 - val_acc: 0.69\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s - loss: 1.3971 - acc: 0.6850 - val_loss: 1.3524 - val_acc: 0.70\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s - loss: 1.3718 - acc: 0.6911 - val_loss: 1.3339 - val_acc: 0.70\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s - loss: 1.3500 - acc: 0.6972 - val_loss: 1.3116 - val_acc: 0.72\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s - loss: 1.3278 - acc: 0.7053 - val_loss: 1.2880 - val_acc: 0.71\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s - loss: 1.3057 - acc: 0.7072 - val_loss: 1.2725 - val_acc: 0.72\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s - loss: 1.2855 - acc: 0.7144 - val_loss: 1.2493 - val_acc: 0.72\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s - loss: 1.2644 - acc: 0.7147 - val_loss: 1.2373 - val_acc: 0.73\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s - loss: 1.2435 - acc: 0.7228 - val_loss: 1.2154 - val_acc: 0.72\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 2s - loss: 1.2265 - acc: 0.7239 - val_loss: 1.2004 - val_acc: 0.73\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s - loss: 1.2092 - acc: 0.7284 - val_loss: 1.1839 - val_acc: 0.74\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 2s - loss: 1.1923 - acc: 0.7301 - val_loss: 1.1697 - val_acc: 0.73\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s - loss: 1.1780 - acc: 0.7324 - val_loss: 1.1509 - val_acc: 0.74\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 2s - loss: 1.1584 - acc: 0.7331 - val_loss: 1.1423 - val_acc: 0.74\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s - loss: 1.1445 - acc: 0.7414 - val_loss: 1.1246 - val_acc: 0.74\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s - loss: 1.1282 - acc: 0.7419 - val_loss: 1.1153 - val_acc: 0.75\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 2s - loss: 1.1106 - acc: 0.7461 - val_loss: 1.0944 - val_acc: 0.75\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s - loss: 1.0957 - acc: 0.7462 - val_loss: 1.0779 - val_acc: 0.75\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 2s - loss: 1.0809 - acc: 0.7507 - val_loss: 1.0696 - val_acc: 0.75\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s - loss: 1.0726 - acc: 0.7498 - val_loss: 1.0671 - val_acc: 0.75\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s - loss: 1.0719 - acc: 0.7494 - val_loss: 1.0596 - val_acc: 0.76\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 2s - loss: 1.0669 - acc: 0.7560 - val_loss: 1.0487 - val_acc: 0.75\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 2s - loss: 1.0511 - acc: 0.7483 - val_loss: 1.0375 - val_acc: 0.76\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 2s - loss: 1.0365 - acc: 0.7540 - val_loss: 1.0161 - val_acc: 0.76\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 2s - loss: 1.0196 - acc: 0.7632 - val_loss: 1.0096 - val_acc: 0.76\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 2s - loss: 1.0081 - acc: 0.7616 - val_loss: 0.9955 - val_acc: 0.76\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s - loss: 0.9940 - acc: 0.7658 - val_loss: 0.9761 - val_acc: 0.77\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s - loss: 0.9808 - acc: 0.7660 - val_loss: 0.9684 - val_acc: 0.77\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 2s - loss: 0.9692 - acc: 0.7730 - val_loss: 0.9569 - val_acc: 0.77\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s - loss: 0.9576 - acc: 0.7751 - val_loss: 0.9485 - val_acc: 0.78\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 2s - loss: 0.9462 - acc: 0.7777 - val_loss: 0.9377 - val_acc: 0.78\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 2s - loss: 0.9369 - acc: 0.7797 - val_loss: 0.9389 - val_acc: 0.78\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 2s - loss: 0.9304 - acc: 0.7795 - val_loss: 0.9256 - val_acc: 0.78\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 2s - loss: 0.9219 - acc: 0.7805 - val_loss: 0.9211 - val_acc: 0.78\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 2s - loss: 0.9106 - acc: 0.7870 - val_loss: 0.9071 - val_acc: 0.78\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 2s - loss: 0.9013 - acc: 0.7862 - val_loss: 0.9077 - val_acc: 0.78\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 2s - loss: 0.8957 - acc: 0.7861 - val_loss: 0.8964 - val_acc: 0.78\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s - loss: 0.8856 - acc: 0.7887 - val_loss: 0.8914 - val_acc: 0.78\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s - loss: 0.8781 - acc: 0.7881 - val_loss: 0.8794 - val_acc: 0.78\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s - loss: 0.8719 - acc: 0.7884 - val_loss: 0.8867 - val_acc: 0.78\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s - loss: 0.8657 - acc: 0.7913 - val_loss: 0.8649 - val_acc: 0.79\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s - loss: 0.8569 - acc: 0.7932 - val_loss: 0.8645 - val_acc: 0.79\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s - loss: 0.8497 - acc: 0.7939 - val_loss: 0.8619 - val_acc: 0.79\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 2s - loss: 0.8449 - acc: 0.7967 - val_loss: 0.8470 - val_acc: 0.79\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s - loss: 0.8384 - acc: 0.7961 - val_loss: 0.8459 - val_acc: 0.79\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 2s - loss: 0.8332 - acc: 0.7959 - val_loss: 0.8419 - val_acc: 0.80\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s - loss: 0.8249 - acc: 0.8028 - val_loss: 0.8282 - val_acc: 0.79\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 2s - loss: 0.8176 - acc: 0.7983 - val_loss: 0.8275 - val_acc: 0.80\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s - loss: 0.8108 - acc: 0.8037 - val_loss: 0.8182 - val_acc: 0.80\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 2s - loss: 0.8083 - acc: 0.8003 - val_loss: 0.8299 - val_acc: 0.80\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s - loss: 0.8061 - acc: 0.8026 - val_loss: 0.8086 - val_acc: 0.80\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s - loss: 0.8043 - acc: 0.8004 - val_loss: 0.8225 - val_acc: 0.80\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 2s - loss: 0.7981 - acc: 0.8038 - val_loss: 0.8088 - val_acc: 0.80\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s - loss: 0.7988 - acc: 0.8013 - val_loss: 0.8042 - val_acc: 0.80\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 2s - loss: 0.7897 - acc: 0.8047 - val_loss: 0.7925 - val_acc: 0.80\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 2s - loss: 0.7814 - acc: 0.8050 - val_loss: 0.7943 - val_acc: 0.80\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s - loss: 0.7753 - acc: 0.8084 - val_loss: 0.7881 - val_acc: 0.80\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s - loss: 0.7680 - acc: 0.8086 - val_loss: 0.7727 - val_acc: 0.81\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s - loss: 0.7619 - acc: 0.8121 - val_loss: 0.7712 - val_acc: 0.81\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 2s - loss: 0.7564 - acc: 0.8133 - val_loss: 0.7636 - val_acc: 0.81\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 2s - loss: 0.7508 - acc: 0.8135 - val_loss: 0.7613 - val_acc: 0.81\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 2s - loss: 0.7455 - acc: 0.8142 - val_loss: 0.7581 - val_acc: 0.81\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 2s - loss: 0.7415 - acc: 0.8170 - val_loss: 0.7506 - val_acc: 0.81\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 2s - loss: 0.7373 - acc: 0.8183 - val_loss: 0.7576 - val_acc: 0.81\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 2s - loss: 0.7363 - acc: 0.8143 - val_loss: 0.7466 - val_acc: 0.82\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 2s - loss: 0.7302 - acc: 0.8205 - val_loss: 0.7421 - val_acc: 0.81\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 2s - loss: 0.7247 - acc: 0.8182 - val_loss: 0.7365 - val_acc: 0.81\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 2s - loss: 0.7201 - acc: 0.8216 - val_loss: 0.7314 - val_acc: 0.81\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 2s - loss: 0.7150 - acc: 0.8201 - val_loss: 0.7302 - val_acc: 0.82\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 2s - loss: 0.7112 - acc: 0.8233 - val_loss: 0.7238 - val_acc: 0.82\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 4s - loss: 0.7075 - acc: 0.8221 - val_loss: 0.7255 - val_acc: 0.82\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 3s - loss: 0.7035 - acc: 0.8253 - val_loss: 0.7206 - val_acc: 0.82\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 3s - loss: 0.6993 - acc: 0.8241 - val_loss: 0.7194 - val_acc: 0.82\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 2s - loss: 0.6962 - acc: 0.8257 - val_loss: 0.7127 - val_acc: 0.82\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 3s - loss: 0.6930 - acc: 0.8249 - val_loss: 0.7144 - val_acc: 0.82\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 2s - loss: 0.6925 - acc: 0.8255 - val_loss: 0.7249 - val_acc: 0.81\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 2s - loss: 0.7086 - acc: 0.8156 - val_loss: 0.7175 - val_acc: 0.81\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 2s - loss: 0.7037 - acc: 0.8200 - val_loss: 0.7219 - val_acc: 0.81\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 2s - loss: 0.6977 - acc: 0.8234 - val_loss: 0.7043 - val_acc: 0.82\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 2s - loss: 0.6916 - acc: 0.8243 - val_loss: 0.7094 - val_acc: 0.82\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 2s - loss: 0.6862 - acc: 0.8289 - val_loss: 0.6987 - val_acc: 0.82\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 2s - loss: 0.6806 - acc: 0.8283 - val_loss: 0.6926 - val_acc: 0.82\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 2s - loss: 0.6746 - acc: 0.8308 - val_loss: 0.6875 - val_acc: 0.82\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 2s - loss: 0.6689 - acc: 0.8309 - val_loss: 0.6793 - val_acc: 0.83\n",
      "Epoch 132/200\n",
      "326/326 [==============================] - 2s - loss: 0.6649 - acc: 0.8326 - val_loss: 0.6791 - val_acc: 0.83\n",
      "Epoch 133/200\n",
      "326/326 [==============================] - 2s - loss: 0.6610 - acc: 0.8336 - val_loss: 0.6779 - val_acc: 0.83\n",
      "Epoch 134/200\n",
      "326/326 [==============================] - 2s - loss: 0.6573 - acc: 0.8338 - val_loss: 0.6749 - val_acc: 0.83\n",
      "Epoch 135/200\n",
      "326/326 [==============================] - 2s - loss: 0.6541 - acc: 0.8335 - val_loss: 0.6699 - val_acc: 0.83\n",
      "Epoch 136/200\n",
      "326/326 [==============================] - 2s - loss: 0.6508 - acc: 0.8352 - val_loss: 0.6739 - val_acc: 0.83\n",
      "Epoch 137/200\n",
      "326/326 [==============================] - 2s - loss: 0.6477 - acc: 0.8366 - val_loss: 0.6659 - val_acc: 0.83\n",
      "Epoch 138/200\n",
      "326/326 [==============================] - 2s - loss: 0.6449 - acc: 0.8346 - val_loss: 0.6684 - val_acc: 0.83\n",
      "Epoch 139/200\n",
      "326/326 [==============================] - 2s - loss: 0.6420 - acc: 0.8372 - val_loss: 0.6598 - val_acc: 0.83\n",
      "Epoch 140/200\n",
      "326/326 [==============================] - 2s - loss: 0.6396 - acc: 0.8356 - val_loss: 0.6610 - val_acc: 0.83\n",
      "Epoch 141/200\n",
      "326/326 [==============================] - 2s - loss: 0.6357 - acc: 0.8382 - val_loss: 0.6550 - val_acc: 0.83\n",
      "Epoch 142/200\n",
      "326/326 [==============================] - 2s - loss: 0.6335 - acc: 0.8372 - val_loss: 0.6581 - val_acc: 0.83\n",
      "Epoch 143/200\n",
      "326/326 [==============================] - 2s - loss: 0.6302 - acc: 0.8394 - val_loss: 0.6523 - val_acc: 0.83\n",
      "Epoch 144/200\n",
      "326/326 [==============================] - 3s - loss: 0.6269 - acc: 0.8393 - val_loss: 0.6503 - val_acc: 0.83\n",
      "Epoch 145/200\n",
      "326/326 [==============================] - 2s - loss: 0.6247 - acc: 0.8397 - val_loss: 0.6474 - val_acc: 0.83\n",
      "Epoch 146/200\n",
      "326/326 [==============================] - 2s - loss: 0.6221 - acc: 0.8406 - val_loss: 0.6481 - val_acc: 0.83\n",
      "Epoch 147/200\n",
      "326/326 [==============================] - 2s - loss: 0.6191 - acc: 0.8410 - val_loss: 0.6429 - val_acc: 0.83\n",
      "Epoch 148/200\n",
      "326/326 [==============================] - 2s - loss: 0.6168 - acc: 0.8419 - val_loss: 0.6451 - val_acc: 0.83\n",
      "Epoch 149/200\n",
      "326/326 [==============================] - 2s - loss: 0.6144 - acc: 0.8416 - val_loss: 0.6385 - val_acc: 0.83\n",
      "Epoch 150/200\n",
      "326/326 [==============================] - 2s - loss: 0.6120 - acc: 0.8418 - val_loss: 0.6436 - val_acc: 0.83\n",
      "Epoch 151/200\n",
      "326/326 [==============================] - 3s - loss: 0.6091 - acc: 0.8428 - val_loss: 0.6325 - val_acc: 0.84\n",
      "Epoch 152/200\n",
      "326/326 [==============================] - 2s - loss: 0.6083 - acc: 0.8420 - val_loss: 0.6511 - val_acc: 0.83\n",
      "Epoch 153/200\n",
      "326/326 [==============================] - 2s - loss: 0.6088 - acc: 0.8420 - val_loss: 0.6367 - val_acc: 0.83\n",
      "Epoch 154/200\n",
      "326/326 [==============================] - 2s - loss: 0.6108 - acc: 0.8399 - val_loss: 0.6393 - val_acc: 0.84\n",
      "Epoch 155/200\n",
      "326/326 [==============================] - 2s - loss: 0.6094 - acc: 0.8419 - val_loss: 0.6287 - val_acc: 0.83\n",
      "Epoch 156/200\n",
      "326/326 [==============================] - 2s - loss: 0.6070 - acc: 0.8415 - val_loss: 0.6304 - val_acc: 0.84\n",
      "Epoch 157/200\n",
      "326/326 [==============================] - 2s - loss: 0.6046 - acc: 0.8427 - val_loss: 0.6263 - val_acc: 0.84\n",
      "Epoch 158/200\n",
      "326/326 [==============================] - 3s - loss: 0.6010 - acc: 0.8428 - val_loss: 0.6301 - val_acc: 0.83\n",
      "Epoch 159/200\n",
      "326/326 [==============================] - 3s - loss: 0.5973 - acc: 0.8446 - val_loss: 0.6228 - val_acc: 0.84\n",
      "Epoch 160/200\n",
      "326/326 [==============================] - 2s - loss: 0.5951 - acc: 0.8433 - val_loss: 0.6304 - val_acc: 0.83\n",
      "Epoch 161/200\n",
      "326/326 [==============================] - 2s - loss: 0.5920 - acc: 0.8451 - val_loss: 0.6198 - val_acc: 0.84\n",
      "Epoch 162/200\n",
      "326/326 [==============================] - 2s - loss: 0.5918 - acc: 0.8445 - val_loss: 0.6212 - val_acc: 0.84\n",
      "Epoch 163/200\n",
      "326/326 [==============================] - 2s - loss: 0.5867 - acc: 0.8469 - val_loss: 0.6190 - val_acc: 0.84\n",
      "Epoch 164/200\n",
      "326/326 [==============================] - 2s - loss: 0.5855 - acc: 0.8460 - val_loss: 0.6167 - val_acc: 0.84\n",
      "Epoch 165/200\n",
      "326/326 [==============================] - 2s - loss: 0.5831 - acc: 0.8460 - val_loss: 0.6119 - val_acc: 0.84\n",
      "Epoch 166/200\n",
      "326/326 [==============================] - 2s - loss: 0.5799 - acc: 0.8466 - val_loss: 0.6133 - val_acc: 0.84\n",
      "Epoch 167/200\n",
      "326/326 [==============================] - 2s - loss: 0.5780 - acc: 0.8478 - val_loss: 0.6109 - val_acc: 0.84\n",
      "Epoch 168/200\n",
      "326/326 [==============================] - 2s - loss: 0.5757 - acc: 0.8472 - val_loss: 0.6105 - val_acc: 0.84\n",
      "Epoch 169/200\n",
      "326/326 [==============================] - 2s - loss: 0.5737 - acc: 0.8483 - val_loss: 0.6067 - val_acc: 0.84\n",
      "Epoch 170/200\n",
      "326/326 [==============================] - 2s - loss: 0.5715 - acc: 0.8482 - val_loss: 0.6072 - val_acc: 0.84\n",
      "Epoch 171/200\n",
      "326/326 [==============================] - 2s - loss: 0.5693 - acc: 0.8495 - val_loss: 0.6039 - val_acc: 0.84\n",
      "Epoch 172/200\n",
      "326/326 [==============================] - 2s - loss: 0.5678 - acc: 0.8487 - val_loss: 0.6049 - val_acc: 0.84\n",
      "Epoch 173/200\n",
      "326/326 [==============================] - 2s - loss: 0.5657 - acc: 0.8495 - val_loss: 0.6043 - val_acc: 0.84\n",
      "Epoch 174/200\n",
      "326/326 [==============================] - 2s - loss: 0.5640 - acc: 0.8504 - val_loss: 0.6018 - val_acc: 0.84\n",
      "Epoch 175/200\n",
      "326/326 [==============================] - 2s - loss: 0.5626 - acc: 0.8497 - val_loss: 0.6066 - val_acc: 0.84\n",
      "Epoch 176/200\n",
      "326/326 [==============================] - 2s - loss: 0.5610 - acc: 0.8502 - val_loss: 0.6003 - val_acc: 0.84\n",
      "Epoch 177/200\n",
      "326/326 [==============================] - 2s - loss: 0.5597 - acc: 0.8504 - val_loss: 0.5994 - val_acc: 0.84\n",
      "Epoch 178/200\n",
      "326/326 [==============================] - 2s - loss: 0.5581 - acc: 0.8499 - val_loss: 0.6000 - val_acc: 0.84\n",
      "Epoch 179/200\n",
      "326/326 [==============================] - 2s - loss: 0.5555 - acc: 0.8516 - val_loss: 0.5949 - val_acc: 0.84\n",
      "Epoch 180/200\n",
      "326/326 [==============================] - 2s - loss: 0.5537 - acc: 0.8505 - val_loss: 0.5997 - val_acc: 0.84\n",
      "Epoch 181/200\n",
      "326/326 [==============================] - 2s - loss: 0.5524 - acc: 0.8520 - val_loss: 0.5958 - val_acc: 0.84\n",
      "Epoch 182/200\n",
      "326/326 [==============================] - 2s - loss: 0.5504 - acc: 0.8509 - val_loss: 0.5991 - val_acc: 0.84\n",
      "Epoch 183/200\n",
      "326/326 [==============================] - 2s - loss: 0.5506 - acc: 0.8517 - val_loss: 0.5926 - val_acc: 0.84\n",
      "Epoch 184/200\n",
      "326/326 [==============================] - 2s - loss: 0.5497 - acc: 0.8513 - val_loss: 0.6046 - val_acc: 0.84\n",
      "Epoch 185/200\n",
      "326/326 [==============================] - 2s - loss: 0.5474 - acc: 0.8534 - val_loss: 0.5910 - val_acc: 0.84\n",
      "Epoch 186/200\n",
      "326/326 [==============================] - 2s - loss: 0.5465 - acc: 0.8523 - val_loss: 0.5962 - val_acc: 0.84\n",
      "Epoch 187/200\n",
      "326/326 [==============================] - 2s - loss: 0.5449 - acc: 0.8527 - val_loss: 0.5888 - val_acc: 0.84\n",
      "Epoch 188/200\n",
      "326/326 [==============================] - 2s - loss: 0.5427 - acc: 0.8532 - val_loss: 0.5952 - val_acc: 0.84\n",
      "Epoch 189/200\n",
      "326/326 [==============================] - 2s - loss: 0.5418 - acc: 0.8528 - val_loss: 0.5851 - val_acc: 0.84\n",
      "Epoch 190/200\n",
      "326/326 [==============================] - 2s - loss: 0.5395 - acc: 0.8530 - val_loss: 0.5889 - val_acc: 0.84\n",
      "Epoch 191/200\n",
      "326/326 [==============================] - 2s - loss: 0.5389 - acc: 0.8544 - val_loss: 0.5844 - val_acc: 0.84\n",
      "Epoch 192/200\n",
      "326/326 [==============================] - 3s - loss: 0.5383 - acc: 0.8531 - val_loss: 0.5862 - val_acc: 0.84\n",
      "Epoch 193/200\n",
      "326/326 [==============================] - 2s - loss: 0.5383 - acc: 0.8533 - val_loss: 0.5831 - val_acc: 0.84\n",
      "Epoch 194/200\n",
      "326/326 [==============================] - 2s - loss: 0.5409 - acc: 0.8519 - val_loss: 0.5935 - val_acc: 0.84\n",
      "Epoch 195/200\n",
      "326/326 [==============================] - 2s - loss: 0.5399 - acc: 0.8540 - val_loss: 0.5813 - val_acc: 0.84\n",
      "Epoch 196/200\n",
      "326/326 [==============================] - 2s - loss: 0.5367 - acc: 0.8518 - val_loss: 0.5775 - val_acc: 0.84\n",
      "Epoch 197/200\n",
      "326/326 [==============================] - 2s - loss: 0.5345 - acc: 0.8533 - val_loss: 0.5807 - val_acc: 0.84\n",
      "Epoch 198/200\n",
      "326/326 [==============================] - 2s - loss: 0.5313 - acc: 0.8552 - val_loss: 0.5798 - val_acc: 0.84\n",
      "Epoch 199/200\n",
      "326/326 [==============================] - 2s - loss: 0.5289 - acc: 0.8552 - val_loss: 0.5777 - val_acc: 0.84\n",
      "Epoch 200/200\n",
      "326/326 [==============================] - 2s - loss: 0.5282 - acc: 0.8556 - val_loss: 0.5788 - val_acc: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13102c0f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betterskill2skill_model.fit(X_train, \n",
    "                            y_train,\n",
    "                            epochs=200, \n",
    "                            batch_size=128, \n",
    "                            shuffle=True,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = betterskill2skill_model.predict(X_test)\n",
    "one_hot_predictions = []\n",
    "for i in np.arange(len(predictions)):\n",
    "    one_hot_layer = []\n",
    "    for j in np.arange(len(predictions[0])):\n",
    "            index_of_max = np.argmax(predictions[i][j])\n",
    "            one_hot_version = np.zeros(skill_num)\n",
    "            one_hot_version[index_of_max] = 1\n",
    "            one_hot_layer.append(one_hot_version)\n",
    "    one_hot_predictions.append(one_hot_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17056932966023874"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate = np.count_nonzero(y_test - one_hot_predictions)/2/(y_test.shape[0] * y_test.shape[1])\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying many different permutations of different hidden layers, optimization functions, acitvation functions, batch sizes, and epoch sizes, many of which returned far less accurate predictions, we have created a small incremental improvement to the model by increasing batch size to 128 and epochs to 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "#### Train a performance prediction model (DKT) using the same 70/30% split and report the accuracy and AUC of prediction on the 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 82 samples\n",
      "Epoch 1/20\n",
      "326/326 [==============================] - 5s - loss: 0.3612 - acc: 0.8561 - val_loss: 0.3264 - val_acc: 0.86\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 4s - loss: 0.3559 - acc: 0.8567 - val_loss: 0.3274 - val_acc: 0.86\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 5s - loss: 0.3556 - acc: 0.8564 - val_loss: 0.3269 - val_acc: 0.87\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 4s - loss: 0.3514 - acc: 0.8571 - val_loss: 0.3273 - val_acc: 0.87\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 5s - loss: 0.3489 - acc: 0.8598 - val_loss: 0.3244 - val_acc: 0.87\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 5s - loss: 0.3478 - acc: 0.8613 - val_loss: 0.3246 - val_acc: 0.87\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 5s - loss: 0.3445 - acc: 0.8618 - val_loss: 0.3232 - val_acc: 0.87\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 5s - loss: 0.3431 - acc: 0.8628 - val_loss: 0.3231 - val_acc: 0.87\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 5s - loss: 0.3413 - acc: 0.8630 - val_loss: 0.3229 - val_acc: 0.87\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 6s - loss: 0.3411 - acc: 0.8634 - val_loss: 0.3238 - val_acc: 0.87\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 5s - loss: 0.3412 - acc: 0.8637 - val_loss: 0.3216 - val_acc: 0.87\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 5s - loss: 0.3379 - acc: 0.8643 - val_loss: 0.3242 - val_acc: 0.87\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 5s - loss: 0.3400 - acc: 0.8647 - val_loss: 0.3238 - val_acc: 0.87\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 5s - loss: 0.3385 - acc: 0.8644 - val_loss: 0.3229 - val_acc: 0.87\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 5s - loss: 0.3372 - acc: 0.8648 - val_loss: 0.3208 - val_acc: 0.87\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 5s - loss: 0.3371 - acc: 0.8647 - val_loss: 0.3225 - val_acc: 0.87\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 5s - loss: 0.3356 - acc: 0.8648 - val_loss: 0.3211 - val_acc: 0.87\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 5s - loss: 0.3338 - acc: 0.8658 - val_loss: 0.3205 - val_acc: 0.87\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 5s - loss: 0.3323 - acc: 0.8666 - val_loss: 0.3209 - val_acc: 0.87\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 6s - loss: 0.3309 - acc: 0.8665 - val_loss: 0.3208 - val_acc: 0.87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e4482b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = skill_response_array[:, 0:-1]\n",
    "skill = skill_array[:, 1:]\n",
    "response = response_array[:, 1:, np.newaxis]\n",
    "\n",
    "x_train, x_test, skill_train, skill_test, response_train, response_test = model_selection.train_test_split(x, skill, response, train_size=0.7, test_size=0.3)\n",
    "\n",
    "dkt_model.fit([x_train, skill_train],\n",
    "              response_train,\n",
    "              epochs=20, \n",
    "              batch_size=32, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dkt_predictions = dkt_model.predict([x_test, skill_test])\n",
    "for i in np.arange(len(dkt_predictions)):\n",
    "    for j in np.arange(len(dkt_predictions[0])):\n",
    "        value = dkt_predictions[i][j][0]\n",
    "        if value >= 0.5:\n",
    "            dkt_predictions[i][j][0] = 1\n",
    "        else:\n",
    "            dkt_predictions[i][j][0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930153810835629"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate = np.count_nonzero(response_test - dkt_predictions)/2/(response_test.shape[0] * response_test.shape[1])\n",
    "1-error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59891534742506813"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "y_true = response_test.flatten()\n",
    "y_score = dkt_predictions.flatten()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy of 92.9% and an AUC of 0.6035."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "#### Tune the hyper parameters of this model to improve accuracy and report your improvement with respect to the tuned parameters. Which lead to the most significant improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 82 samples\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 5s - loss: 0.3354 - acc: 0.8665 - val_loss: 0.3256 - val_acc: 0.86\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 4s - loss: 0.3337 - acc: 0.8672 - val_loss: 0.3257 - val_acc: 0.86\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 5s - loss: 0.3318 - acc: 0.8678 - val_loss: 0.3263 - val_acc: 0.86\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 6s - loss: 0.3311 - acc: 0.8677 - val_loss: 0.3265 - val_acc: 0.86\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 6s - loss: 0.3295 - acc: 0.8682 - val_loss: 0.3265 - val_acc: 0.86\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 5s - loss: 0.3298 - acc: 0.8686 - val_loss: 0.3278 - val_acc: 0.86\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 4s - loss: 0.3285 - acc: 0.8685 - val_loss: 0.3267 - val_acc: 0.86\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 4s - loss: 0.3273 - acc: 0.8692 - val_loss: 0.3275 - val_acc: 0.86\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 4s - loss: 0.3263 - acc: 0.8692 - val_loss: 0.3285 - val_acc: 0.86\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 6s - loss: 0.3260 - acc: 0.8695 - val_loss: 0.3288 - val_acc: 0.86\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 6s - loss: 0.3248 - acc: 0.8700 - val_loss: 0.3283 - val_acc: 0.86\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 5s - loss: 0.3238 - acc: 0.8701 - val_loss: 0.3282 - val_acc: 0.86\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 4s - loss: 0.3236 - acc: 0.8699 - val_loss: 0.3291 - val_acc: 0.86\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 5s - loss: 0.3239 - acc: 0.8702 - val_loss: 0.3299 - val_acc: 0.86\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 5s - loss: 0.3241 - acc: 0.8705 - val_loss: 0.3300 - val_acc: 0.86\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 5s - loss: 0.3230 - acc: 0.8707 - val_loss: 0.3305 - val_acc: 0.86\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 4s - loss: 0.3235 - acc: 0.8705 - val_loss: 0.3296 - val_acc: 0.86\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 4s - loss: 0.3212 - acc: 0.8714 - val_loss: 0.3306 - val_acc: 0.86\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 5s - loss: 0.3219 - acc: 0.8702 - val_loss: 0.3306 - val_acc: 0.86\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 4s - loss: 0.3217 - acc: 0.8708 - val_loss: 0.3317 - val_acc: 0.86\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 4s - loss: 0.3225 - acc: 0.8701 - val_loss: 0.3315 - val_acc: 0.86\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 4s - loss: 0.3208 - acc: 0.8711 - val_loss: 0.3324 - val_acc: 0.86\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 5s - loss: 0.3212 - acc: 0.8711 - val_loss: 0.3315 - val_acc: 0.86\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 4s - loss: 0.3188 - acc: 0.8723 - val_loss: 0.3320 - val_acc: 0.86\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 4s - loss: 0.3172 - acc: 0.8724 - val_loss: 0.3318 - val_acc: 0.86\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 4s - loss: 0.3168 - acc: 0.8723 - val_loss: 0.3323 - val_acc: 0.86\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 4s - loss: 0.3163 - acc: 0.8726 - val_loss: 0.3326 - val_acc: 0.86\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 4s - loss: 0.3165 - acc: 0.8725 - val_loss: 0.3325 - val_acc: 0.86\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 4s - loss: 0.3163 - acc: 0.8731 - val_loss: 0.3329 - val_acc: 0.86\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 4s - loss: 0.3147 - acc: 0.8731 - val_loss: 0.3335 - val_acc: 0.86\n",
      "error rate: 0.06841138659320478\n"
     ]
    }
   ],
   "source": [
    "x = skill_response_array[:, 0:-1]\n",
    "skill = skill_array[:, 1:]\n",
    "response = response_array[:, 1:, np.newaxis]\n",
    "\n",
    "x_train, x_test, skill_train, skill_test, response_train, response_test = model_selection.train_test_split(x, skill, response, train_size=0.7, test_size=0.3)\n",
    "\n",
    "dkt_model.fit([x_train, skill_train],\n",
    "              response_train,\n",
    "              epochs=30, \n",
    "              batch_size=38, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)\n",
    "\n",
    "dkt_predictions = dkt_model.predict([x_test, skill_test])\n",
    "for i in np.arange(len(dkt_predictions)):\n",
    "    for j in np.arange(len(dkt_predictions[0])):\n",
    "        value = dkt_predictions[i][j][0]\n",
    "        if value >= 0.5:\n",
    "            dkt_predictions[i][j][0] = 1\n",
    "        else:\n",
    "            dkt_predictions[i][j][0] = 0\n",
    "\n",
    "error_rate = np.count_nonzero(response_test - dkt_predictions)/2/(response_test.shape[0] * response_test.shape[1])\n",
    "print(\"error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.606662474798\n"
     ]
    }
   ],
   "source": [
    "y_true = response_test.flatten()\n",
    "y_score = dkt_predictions.flatten()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"auc:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned the hyperparameters by increasing epochs to 30 and batch size to 38.\n",
    "We increased the number of epochs because the longer we train the model, the better the model is able to understand the underlying patterns. We increased the batch size because in the input, the model is able to find relationships between different students more effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
