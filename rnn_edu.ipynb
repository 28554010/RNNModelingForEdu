{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Edu\n",
    "Vinitra Swamy, Madeline Wu, Wilton Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics \n",
    "\n",
    "filename = 'skill_builder_data_corrected.csv'\n",
    "df = pd.read_csv(filename, encoding='ISO-8859-1', low_memory=False)\n",
    "df = df[(df['original'] == 1) & (df['attempt_count'] == 1) & ~(df['skill_name'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets():\n",
    "    users_list = df['user_id'].unique()\n",
    "    skill_list = df['skill_name'].unique()\n",
    "    \n",
    "    skill_dict = dict(zip(skill_list, np.arange(len(skill_list), dtype='int32') + 1))\n",
    "    response_list = []\n",
    "    skill_list = []\n",
    "    assistment_list = []\n",
    "    \n",
    "    counter = 0\n",
    "    for user in users_list:\n",
    "        sub_df = df[df['user_id'] == user]\n",
    "        if len(sub_df) > 100:\n",
    "            first_hundred = sub_df.iloc[0:100]\n",
    "            response_df = pd.DataFrame(index=[counter], columns=['student_id']+['r'+str(i) for i in range(100)])\n",
    "            skill_df = pd.DataFrame(index=[counter], columns=['student_id']+['s'+str(i) for i in range(100)])\n",
    "            assistment_df = pd.DataFrame(index=[counter], columns=['student_id']+['a'+str(i) for i in range(100)])\n",
    "            \n",
    "            response_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            skill_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            assistment_df.iloc[0, 0] = first_hundred.iloc[0]['user_id']\n",
    "            for i in range(100):\n",
    "                response_df.iloc[0, i+1] = first_hundred.iloc[i]['correct']\n",
    "                skill_df.iloc[0, i+1] = skill_dict[first_hundred.iloc[i]['skill_name']]\n",
    "                assistment_df.iloc[0, i+1] = first_hundred.iloc[i]['assistment_id']\n",
    "            counter += 1\n",
    "            response_list.append(response_df)\n",
    "            skill_list.append(skill_df)\n",
    "            assistment_list.append(assistment_df)\n",
    "    \n",
    "    response_df = pd.concat(response_list)\n",
    "    skill_df = pd.concat(skill_list)\n",
    "    assistment_df = pd.concat(assistment_list)\n",
    "    \n",
    "    return skill_dict, response_df, skill_df, assistment_df\n",
    "    \n",
    "skill_dict, response_df, skill_df, assistment_df = generate_datasets()\n",
    "\n",
    "with open('skill_dict.json', 'w', encoding='utf-8') as f:\n",
    "    to_dump_dict = {}\n",
    "    for key, value in skill_dict.items():\n",
    "        to_dump_dict[key] = str(value)\n",
    "    json.dump(to_dump_dict, f)\n",
    "response_df.to_csv('correct.tsv', sep='\\t')\n",
    "skill_df.to_csv('skill.tsv', sep='\\t')\n",
    "assistment_df.to_csv('assistment_id.tsv', sep='\\t')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.read_csv('correct.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "skill_df = pd.read_csv('skill.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "assistment_df = pd.read_csv('assistment_id.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "skill_dict = {}\n",
    "with open('skill_dict.json', 'r', encoding='utf-8') as f:\n",
    "    loaded = json.load(f)\n",
    "    for k, v in loaded.items():\n",
    "        skill_dict[k] = int(v)\n",
    "\n",
    "skill_num = len(skill_dict) + 1 # including 0\n",
    "\n",
    "def one_hot(skill_matrix, vocab_size):\n",
    "    '''\n",
    "    params:\n",
    "        skill_matrix: 2-D matrix (student, skills)\n",
    "        vocal_size: size of the vocabulary\n",
    "    returns:\n",
    "        a ndarray with a shape like (student, sequence_len, vocab_size)\n",
    "    '''\n",
    "    seq_len = skill_matrix.shape[1]\n",
    "    result = np.zeros((skill_matrix.shape[0], seq_len, vocab_size))\n",
    "    for i in range(skill_matrix.shape[0]):\n",
    "        result[i, np.arange(seq_len), skill_matrix[i]] = 1.\n",
    "    return result\n",
    "\n",
    "def dkt_one_hot(skill_matrix, response_matrix, vocab_size):\n",
    "    seq_len = skill_matrix.shape[1]\n",
    "    skill_response_array = np.zeros((skill_matrix.shape[0], seq_len, 2 * vocab_size))\n",
    "    masking_array = np.zeros((skill_matrix.shape[0], seq_len, 2 * vocab_size))\n",
    "    for i in range(skill_matrix.shape[0]):\n",
    "        skill_response_array[i, np.arange(seq_len), 2 * skill_matrix[i] + response_matrix[i]] = 1.\n",
    "        masking_array[i, np.arange(seq_len), 2 * skill_matrix[i]] = 1.\n",
    "        masking_array[i, np.arange(seq_len), 2 * skill_matrix[i] + 1] = 1.\n",
    "    return skill_response_array, masking_array\n",
    "\n",
    "def preprocess(skill_df, response_df, skill_num):\n",
    "    skill_matrix = skill_df.iloc[:, 1:].values\n",
    "    response_array = response_df.iloc[:, 1:].values\n",
    "    skill_array = one_hot(skill_matrix, skill_num)\n",
    "    skill_response_array, masking_array = dkt_one_hot(skill_matrix, response_array, skill_num)\n",
    "    return skill_array, response_array, skill_response_array, masking_array\n",
    "    \n",
    "\n",
    "skill_array, response_array, skill_response_array, masking_array = preprocess(skill_df, response_df, skill_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed, Lambda, multiply\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "\n",
    "def build_skill2skill_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input = Input(shape=input_shape)\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout)(input)\n",
    "    output = TimeDistributed(Dense(input_shape[-1], activation='softmax'), name='probability')(lstm)\n",
    "    model = Model(inputs=[input], outputs=[output])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def reduce_dim(x):\n",
    "    x = K.max(x, axis=-1, keepdims=True)\n",
    "    return x\n",
    "\n",
    "def build_dkt_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input_skills = Input(shape=input_shape)\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout)(input_skills)\n",
    "    dense = TimeDistributed(Dense(input_shape[-1], activation='sigmoid'))(lstm)\n",
    "    \n",
    "    skill_next = Input(shape=input_shape)\n",
    "    merged = multiply([dense, skill_next])\n",
    "    reduced = Lambda(reduce_dim, output_shape=(input_shape[0], 1))(merged)\n",
    "    \n",
    "    model = Model(inputs=[input_skills, skill_next], outputs=[reduced])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "print('skill2skill')\n",
    "skill2skill_model = build_skill2skill_model((99, skill_num), lstm_dim=64)\n",
    "\n",
    "print('dkt')\n",
    "dkt_model = build_dkt_model((99, 2 * skill_num), lstm_dim=64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train skill2skill\n",
    "skill2skill_model.fit(skill_array[:, 0:-1], \n",
    "                      skill_array[:, 1:],\n",
    "                      epochs=20, \n",
    "                      batch_size=32, \n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkt_model.fit([skill_response_array[:, 0:-1], masking_array[:, 1:]],\n",
    "              response_array[:, 1:, np.newaxis],\n",
    "              epochs=20, \n",
    "              batch_size=32, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "#### What were the 5 most common and 5 least common skills in this dataset? What percentage of responses are associated with the most common skill?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 most common skills were: 87: Equation Solving Two or Fewer Steps, 30: Conversion of Fraction Decimals Percents, 71: Addition and Subtraction Fractions, 68: Addition and Subtraction Integers, 33: Ordering Fractions. \n",
    "\n",
    "The 5 least common skills were: 28: Reading a Ruler or Scale, 102: Recognize Quadratic Pattern, 98: Finding Slope from Ordered Pairs, 96: Finding Slope From Situation, 99: Distributive Property.\n",
    "\n",
    "87 (Equation Solving Two or Fewer Steps) was the most common skill.\n",
    "\n",
    "5.77% of the responses corresponded with this skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.groupby(by=['skill_name']).count()\n",
    "\n",
    "most = sorted_df.sort_values(by='order_id', ascending=[False]).index[0:5]\n",
    "print(\"5 most common skills are:\", [str(skill_dict[skill]) + \": \" + skill for skill in most])\n",
    "\n",
    "least = sorted_df.sort_values(by='order_id', ascending=[True]).index[0:5]\n",
    "print(\"5 least common skills are:\", [str(skill_dict[skill]) + \": \" + skill for skill in least])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_df = sorted_df.sort_values(by='order_id', ascending=[False])\n",
    "total = most_df.ix[:,0].sum()\n",
    "most_common_skill = most_df.iloc[0,0]\n",
    "\n",
    "most_common_skill / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "#### Train the sequence prediction model using a randomly selected 70% (training set) of students' data and predict on the remaining 30% (test set). What was the overall accuracy of skill prediction in the test set? What were the top 5 hardest and easiest to predict skills? Describe the metric you chose to represent hard/easy prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = skill_array[:, 0:-1]\n",
    "y = skill_array[:, 1:]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, test_size=0.3)\n",
    "\n",
    "skill2skill_model.fit(X_train, \n",
    "                      y_train,\n",
    "                      epochs=20, \n",
    "                      batch_size=32, \n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = skill2skill_model.predict(X_test)\n",
    "one_hot_predictions = []\n",
    "for i in np.arange(len(predictions)):\n",
    "    one_hot_layer = []\n",
    "    for j in np.arange(len(predictions[0])):\n",
    "            index_of_max = np.argmax(predictions[i][j])\n",
    "            one_hot_version = np.zeros(skill_num)\n",
    "            one_hot_version[index_of_max] = 1\n",
    "            one_hot_layer.append(one_hot_version)\n",
    "    one_hot_predictions.append(one_hot_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = np.count_nonzero(y_test - one_hot_predictions)/2/(y_test.shape[0] * y_test.shape[1])\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying top 5 hardest/easiest to predict skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "one_hot_predictions - y_test\n",
    "\n",
    "correct = {}\n",
    "incorrect = {}\n",
    "\n",
    "for i in range(len(one_hot_predictions)):\n",
    "    for j in range(len(one_hot_predictions[0])):\n",
    "        prediction = one_hot_predictions[i][j]\n",
    "        actual = y_test[i][j]\n",
    "        \n",
    "        comparison = prediction - actual\n",
    "        position = np.argmax(actual) + 1\n",
    "        if 1 not in comparison and -1 not in comparison:\n",
    "            if position in correct.keys():\n",
    "                correct[position] += 1\n",
    "            else:\n",
    "                correct[position] = 1\n",
    "        else:\n",
    "            if position in incorrect.keys():\n",
    "                incorrect[position] += 1\n",
    "            else:\n",
    "                incorrect[position] = 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.arange(1, 112):\n",
    "    if i not in correct.keys():\n",
    "        correct[i] = 0\n",
    "    if i not in incorrect.keys():\n",
    "        incorrect[i] = 0\n",
    "        \n",
    "totals = [correct[i] + incorrect[i] for i in np.arange(1, 112)]\n",
    "for i in range(1, len(correct)+1):\n",
    "#     correct_key = list(correct.keys())[i]\n",
    "#     incorrect_key = list(incorrect.keys())[i]\n",
    "#     print(correct[i], incorrect[i], totals[i-1])\n",
    "\n",
    "    if totals[i-1] != 0:\n",
    "        correct[i] = correct[i] / totals[i-1]\n",
    "        incorrect[i] = incorrect[i] / totals[i-1]\n",
    "    else:\n",
    "        if correct[i] != 0 or incorrect[i] != 0:\n",
    "            print(\"something is incorrect lol\")\n",
    "\n",
    "sorted_correct = sorted(correct.items(), key=operator.itemgetter(1))\n",
    "easiest_to_identify_skills = sorted_correct[-5:]\n",
    "sorted_incorrect = sorted(incorrect.items(), key=operator.itemgetter(1))\n",
    "hardest_to_identify_skills = sorted_incorrect[-5:]\n",
    "\n",
    "easiest_to_identify_skills, hardest_to_identify_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined easiest to identify skills as the skills that had the highest proportion of accurate prediction. We decided not to use mere accurate prediction as a metric because it is unfair to skills that don't appear as often in the dataset. We defined hardest to identify skills analogously -- those that had the highest proportion in the cases of inaccurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "#### Modify parameters of the network to increase accuracy (e.g. number of hidden nodes, optimizer, number of RNN layers, number of epochs, creating a validation set and stopping training when the validation set accuracy decreases). What were your accuracy results with respect to the hyper parameters you tuned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_betterskill2skill_model(input_shape, lstm_dim=32, dropout=0.0):\n",
    "    input = Input(shape=input_shape)\n",
    "    lstm = LSTM(lstm_dim, \n",
    "                return_sequences=True, \n",
    "                dropout=dropout)(input)\n",
    "    output = TimeDistributed(Dense(input_shape[-1], activation='softmax'), name='probability')(lstm)\n",
    "    model = Model(inputs=[input], outputs=[output])\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "print('betterskill2skill')\n",
    "betterskill2skill_model = build_betterskill2skill_model((99, skill_num), lstm_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betterskill2skill_model.fit(X_train, \n",
    "                            y_train,\n",
    "                            epochs=200, \n",
    "                            batch_size=128, \n",
    "                            shuffle=True,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = betterskill2skill_model.predict(X_test)\n",
    "one_hot_predictions = []\n",
    "for i in np.arange(len(predictions)):\n",
    "    one_hot_layer = []\n",
    "    for j in np.arange(len(predictions[0])):\n",
    "            index_of_max = np.argmax(predictions[i][j])\n",
    "            one_hot_version = np.zeros(skill_num)\n",
    "            one_hot_version[index_of_max] = 1\n",
    "            one_hot_layer.append(one_hot_version)\n",
    "    one_hot_predictions.append(one_hot_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = np.count_nonzero(y_test - one_hot_predictions)/2/(y_test.shape[0] * y_test.shape[1])\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying many different permutations of different hidden layers, optimization functions, acitvation functions, batch sizes, and epoch sizes, many of which returned far less accurate predictions, we have created a small incremental improvement to the model by increasing batch size to 128 and epochs to 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "#### Train a performance prediction model (DKT) using the same 70/30% split and report the accuracy and AUC of prediction on the 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = skill_response_array[:, 0:-1]\n",
    "masking = masking_array[:, 1:]\n",
    "response = response_array[:, 1:, np.newaxis]\n",
    "\n",
    "x_train, x_test, masking_train, masking_test, response_train, response_test = model_selection.train_test_split(x, masking, response, train_size=0.7, test_size=0.3)\n",
    "\n",
    "dkt_model.fit([x_train, masking_train],\n",
    "              response_train,\n",
    "              epochs=20, \n",
    "              batch_size=32, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkt_predictions = dkt_model.predict([x_test, masking_test])\n",
    "for i in np.arange(len(dkt_predictions)):\n",
    "    for j in np.arange(len(dkt_predictions[0])):\n",
    "        value = dkt_predictions[i][j][0]\n",
    "        if value >= 0.5:\n",
    "            dkt_predictions[i][j][0] = 1\n",
    "        else:\n",
    "            dkt_predictions[i][j][0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = np.count_nonzero(response_test - dkt_predictions)/2/(response_test.shape[0] * response_test.shape[1])\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "y_true = response_test.flatten()\n",
    "y_score = dkt_predictions.flatten()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an error rate of 7.17% and an AUC of 0.5799."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "#### Tune the hyper parameters of this model to improve accuracy and report your improvement with respect to the tuned parameters. Which lead to the most significant improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = skill_response_array[:, 0:-1]\n",
    "masking = masking_array[:, 1:]\n",
    "response = response_array[:, 1:, np.newaxis]\n",
    "\n",
    "x_train, x_test, masking_train, masking_test, response_train, response_test = model_selection.train_test_split(x, masking, response, train_size=0.7, test_size=0.3)\n",
    "\n",
    "dkt_model.fit([x_train, masking_train],\n",
    "              response_train,\n",
    "              epochs=30, \n",
    "              batch_size=38, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2)\n",
    "\n",
    "dkt_predictions = dkt_model.predict([x_test, masking_test])\n",
    "for i in np.arange(len(dkt_predictions)):\n",
    "    for j in np.arange(len(dkt_predictions[0])):\n",
    "        value = dkt_predictions[i][j][0]\n",
    "        if value >= 0.5:\n",
    "            dkt_predictions[i][j][0] = 1\n",
    "        else:\n",
    "            dkt_predictions[i][j][0] = 0\n",
    "\n",
    "error_rate = np.count_nonzero(response_test - dkt_predictions)/2/(response_test.shape[0] * response_test.shape[1])\n",
    "print(\"error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = response_test.flatten()\n",
    "y_score = dkt_predictions.flatten()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"auc:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned the hyperparameters by increasing epochs to 30 and batch size to 38.\n",
    "We increased the number of epochs because the longer we train the model, the better the model is able to understand the underlying patterns. We increased the batch size because in the input, the model is able to find relationships between different students more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
